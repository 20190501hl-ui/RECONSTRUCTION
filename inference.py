#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šé˜¶æ®µé‡æ„æ¨ç†æ¨¡å—
ç”Ÿæˆä¸‰ä¸ªæ—¶é—´æ­¥çš„é‡æ„å›¾åƒï¼š50%, 80%, 100%
"""

import argparse
import os
import pickle
import torch
import torch.utils.checkpoint
from datasets import Dataset
from diffusers import StableDiffusionPipeline
from PIL import Image
from diffusers.pipelines.stable_diffusion import safety_checker

def sc(self, clip_input, images): 
    return images, [False for i in images]

safety_checker.StableDiffusionSafetyChecker.forward = sc

def safe_torch_load(file_path):
    """å®‰å…¨åŠ è½½åŒ…å«PIL.Imageå¯¹è±¡çš„torchæ–‡ä»¶"""
    try:
        # é¦–å…ˆå°è¯•é»˜è®¤åŠ è½½
        return torch.load(file_path)
    except (RuntimeError, pickle.PicklingError, Exception) as e:
        error_msg = str(e).lower()
        if any(keyword in error_msg for keyword in ["weights_only", "pil.image", "weightspickler", "unsupported global"]):
            # å¦‚æœæ˜¯PyTorch 2.6+çš„å®‰å…¨åŠ è½½é—®é¢˜ï¼Œä½¿ç”¨weights_only=False
            print(f"ä½¿ç”¨å…¼å®¹æ¨¡å¼åŠ è½½ {file_path} (PyTorch 2.6+)")
            return torch.load(file_path, weights_only=False)
        else:
            raise e

class MultistageInference:
    def __init__(self, model_path, output_dir, device="cuda"):
        self.model_path = model_path
        self.output_dir = output_dir
        self.device = device
        self.pipeline = None
        
    def load_pipeline(self):
        """åŠ è½½Stable Diffusion Pipeline"""
        print(f"Loading pipeline from {self.model_path}...")
        self.pipeline = StableDiffusionPipeline.from_pretrained(
            self.model_path,
            revision=None,
            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
            safety_checker=None,
            requires_safety_checker=False
        )
        
        # åŠ è½½LoRAæƒé‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if os.path.exists("output_lora"):
            try:
                self.pipeline.unet.load_attn_procs("output_lora")
                print(f"âœ… Loaded LoRA weights from output_lora/")
            except Exception as e:
                print(f"âš ï¸ Failed to load LoRA weights: {e}")
                print("ğŸ”§ Using base Stable Diffusion model without LoRA")
        else:
            print("âš ï¸ LoRA weights not found, using base Stable Diffusion model")
        
        self.pipeline.to(self.device)
        print("âœ… Pipeline loaded successfully!")
    
    def generate_single_stage(self, dataset, save_dir, num_images=3, inference_steps=30, seed=1337):
        """ç”Ÿæˆå•é˜¶æ®µé‡æ„å›¾åƒï¼ˆåŸºçº¿æ–¹æ³•ï¼‰"""
        print(f"Generating single-stage images to {save_dir}...")
        
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)
        
        torch.manual_seed(seed)
        
        for i in range(len(dataset["text"])):
            for j in range(num_images):
                image = self.pipeline(
                    dataset["text"][i], 
                    num_inference_steps=inference_steps,
                    guidance_scale=7.5,
                    generator=torch.Generator(device=self.device).manual_seed(seed + i * 100 + j)
                ).images[0]
                
                filename = f"image_{i+1:02}_{j+1:02}.jpg"
                save_path = os.path.join(save_dir, filename)
                image.save(save_path)
            
            if (i + 1) % 10 == 0:
                print(f"Processed {i + 1}/{len(dataset['text'])} samples (single-stage)")
    
    def generate_multistage(self, dataset, save_dir, num_images=3, inference_steps=30, seed=1337):
        """ç”Ÿæˆä¸‰é˜¶æ®µé‡æ„å›¾åƒï¼ˆåˆ›æ–°æ–¹æ³•ï¼‰"""
        print(f"Generating multistage images to {save_dir}...")
        
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)
        
        torch.manual_seed(seed)
        
        # ä¸‰ä¸ªé‡æ„é˜¶æ®µï¼š50%, 80%, 100%
        timestep_ratios = [0.5, 0.8, 1.0]
        timesteps = [int(inference_steps * ratio) for ratio in timestep_ratios]
        
        print(f"Multistage reconstruction with timesteps: {timesteps}")
        
        for i in range(len(dataset["text"])):
            prompt = dataset["text"][i]
            for stage_idx, steps in enumerate(timesteps):
                for j in range(num_images):
                    image = self.pipeline(
                        prompt,
                        num_inference_steps=steps,
                        guidance_scale=7.5,
                        generator=torch.Generator(device=self.device).manual_seed(seed + i * 100 + j)
                    ).images[0]
                    
                    # æ ¼å¼: image_01_s1_01.jpg (å›¾åƒID_é˜¶æ®µ_æ ·æœ¬ID)
                    filename = f"image_{i+1:02}_s{stage_idx+1}_{j+1:02}.jpg"
                    save_path = os.path.join(save_dir, filename)
                    image.save(save_path)
            
            if (i + 1) % 5 == 0:
                print(f"Processed {i + 1}/{len(dataset['text'])} samples (multistage)")

def main():
    # å†…ç½®å‚æ•°é…ç½®
    config = {
        "model_path": "runwayml/stable-diffusion-v1-5",
        "lora_dir": "output_lora",
        "data_path": "data/test_dataset.pt",
        "single_save_dir": "result/single_stage_images",
        "multi_save_dir": "result/multi_stage_images", 
        "num_images": 3,
        "inference_steps": 15,
        "seed": 1337,
        "device": "cuda" if torch.cuda.is_available() else "cpu"
    }
    
    print("=" * 60)
    print("å¤šé˜¶æ®µé‡æ„æ”»å‡» - å›¾åƒç”Ÿæˆæ¨¡å—")
    print("=" * 60)
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    if not os.path.exists(config["data_path"]):
        print(f"Error: Data file not found: {config['data_path']}")
        print("Please make sure the dataset is in the correct location.")
        return
    
    # åˆå§‹åŒ–æ¨ç†å™¨
    inferencer = MultistageInference(
        model_path=config["model_path"],
        output_dir=config["lora_dir"],
        device=config["device"]
    )
    
    # åŠ è½½pipeline
    try:
        inferencer.load_pipeline()
    except Exception as e:
        print(f"Error loading pipeline: {e}")
        return
    
    # åŠ è½½æ•°æ®é›†
    print(f"Loading dataset from {config['data_path']}...")
    dataset = Dataset.from_dict(safe_torch_load(config["data_path"]))
    print(f"Loaded {len(dataset)} samples")
    
    # ç”Ÿæˆå•é˜¶æ®µå›¾åƒï¼ˆåŸºçº¿ï¼‰
    print("\nStep 1: Generating single-stage images (baseline)...")
    inferencer.generate_single_stage(
        dataset=dataset,
        save_dir=config["single_save_dir"],
        num_images=config["num_images"],
        inference_steps=config["inference_steps"],
        seed=config["seed"]
    )
    
    # ç”Ÿæˆå¤šé˜¶æ®µå›¾åƒï¼ˆåˆ›æ–°æ–¹æ³•ï¼‰
    print("\nStep 2: Generating multistage images (our method)...")
    inferencer.generate_multistage(
        dataset=dataset,
        save_dir=config["multi_save_dir"],
        num_images=config["num_images"],
        inference_steps=config["inference_steps"],
        seed=config["seed"]
    )
    
    print("\n" + "=" * 60)
    print("å›¾åƒç”Ÿæˆå®Œæˆ!")
    print(f"å•é˜¶æ®µå›¾åƒä¿å­˜åœ¨: {config['single_save_dir']}")
    print(f"å¤šé˜¶æ®µå›¾åƒä¿å­˜åœ¨: {config['multi_save_dir']}")
    print("æ¥ä¸‹æ¥è¯·è¿è¡Œç‰¹å¾æå–: python extract_features.py")
    print("=" * 60)

if __name__ == "__main__":
    main()